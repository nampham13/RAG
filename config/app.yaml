# RAG System Configuration
paths:
  data_dir: "data"
  prompt_path: "prompts"

ui:
  default_backend: "gemini"

llm:
  gemini:
    # API key is read from .streamlit/secrets.toml
    model: "gemini-2.0-flash"
    temperature: 0.7
    max_tokens: 2048

  lmstudio:
    base_url: "http://localhost:1234"
    model: "local-model"
    temperature: 0.7
    max_tokens: 2048